{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/chatGPT/blob/main/Open_Interpreter_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dT4HzysPiaGl"
      },
      "source": [
        "# Welcome!\n",
        "\n",
        "**Open Interpreter** is an open-source project that lets GPT-4 execute Python code locally ‚Äî or in this case, in Google Colab.\n",
        "\n",
        "In this demo notebook, we'll explore a few powerful use-cases for Open Interpreter:\n",
        "\n",
        "1. Writing and editing dozens of documents based on some criteria.\n",
        "2. Creating \"slowed and reverbed\" versions of songs with just a YouTube link.\n",
        "3. Redrawing every frame in a music video with Stable Diffusion.\n",
        "\n",
        "Now, grab a drink + an `OPENAI_API_KEY` and let's get started!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N72lFowc2GZv"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW6EmHRli1fN"
      },
      "source": [
        "First, let's install `open-interpreter`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4pDQ5xE-lokf"
      },
      "outputs": [],
      "source": [
        "!pip install open-interpreter --q\n",
        "# Google Colab users: restart your runtime here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYHe0KLri7lU"
      },
      "source": [
        "You'll need an OpenAI API key to use Open Interpreter. You can [get one here](https://platform.openai.com/account/api-keys)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Deep_learning/api.txt\") as file:\n",
        "    #text = file.read()\n",
        "    i=1\n",
        "    key = []\n",
        "    while True:\n",
        "        include_break_line = file.readline() #ÊîπË°å„ÅåÂê´„Åæ„Çå„ÅüË°å\n",
        "        line = include_break_line.rstrip() #ÊîπË°å„ÇíÂèñ„ÇäÈô§„Åè\n",
        "        if line: #key„ÅÆË™≠„ÅøËæº„Åø\n",
        "            #print(f'{i}Ë°åÁõÆÔºö{line}')\n",
        "            key.append(line)\n",
        "            i += 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "# API„Ç≠„Éº„ÅÆÊ∫ñÂÇô\n",
        "# #ngrok_aceess_token = key[5]\n",
        "#openai_api_key = key[3]\n",
        "# deepl_auth_key = key[1]\n",
        "# serp_api_key = key[7]\n",
        "\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = key[3]\n",
        "os.environ[\"SERPAPI_API_KEY\"] = key[7]\n",
        "os.environ[\"GOOGLE_CSE_ID\"] = key[9]\n",
        "os.environ[\"GOOGLE_API_KEY\"] = key[11]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNc1ijbrsV6m",
        "outputId": "9fb3c8d6-d201-400c-a5be-1761d6f5c840"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SCEh9l8LZqcL"
      },
      "outputs": [],
      "source": [
        "import interpreter\n",
        "\n",
        "# Paste your OpenAI API key below.\n",
        "interpreter.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "serp_api_key = os.environ[\"SERPAPI_API_KEY\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**By default, Open Interpreter will ask for confirmation before executing any code.**\n",
        "\n",
        "Since Google Colab is a safe, isolated environment, we recommend enabling `auto_run`. This mimics the behavior of OpenAI's code interpreter."
      ],
      "metadata": {
        "id": "6hQubS1mFe8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter.auto_run = True"
      ],
      "metadata": {
        "id": "CrI5b2IAFeDk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Achievements\n"
      ],
      "metadata": {
        "id": "Y6b5u0gWBFY3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scrape PubMed to extract publication titles"
      ],
      "metadata": {
        "id": "I55InGL1BSdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Define the URL of the search results\n",
        "url = 'https://pubmed.ncbi.nlm.nih.gov/?term=IgG4-ROD'\n",
        "\n",
        "# Send a GET request to the server\n",
        "response = requests.get(url)\n",
        "\n",
        "# Print the status code (should be 200 for success)\n",
        "print(response.status_code)"
      ],
      "metadata": {
        "id": "zgJab-ZCTFOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Find all elements that contain the titles of the papers and the links to the detail pages\n",
        "title_link_elements = soup.find_all('a', class_='docsum-title', limit=10)\n",
        "\n",
        "# Extract the titles and the links\n",
        "titles = [element.text.strip() for element in title_link_elements]\n",
        "links = ['https://pubmed.ncbi.nlm.nih.gov' + element['href'] for element in title_link_elements]\n",
        "\n",
        "# Print the first few titles and links to check if we're on the right track\n",
        "print(titles[:3])\n",
        "print(links[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "id": "ZXZCwJIBTNN8",
        "outputId": "d84ca922-8ac3-4345-a64b-fd528f01c58a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['IgG4-related disease in the eye and ocular adnexa.', 'IgG4-related disease: a neuro-ophthalmological \n",
              "perspective.', 'IgG4-Related Ophthalmic Disease. Part II: Clinical Aspects.']\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">['IgG4-related disease in the eye and ocular adnexa.', 'IgG4-related disease: a neuro-ophthalmological \n",
              "perspective.', 'IgG4-Related Ophthalmic Disease. Part II: Clinical Aspects.']\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['https://pubmed.ncbi.nlm.nih.gov/28858963/', 'https://pubmed.ncbi.nlm.nih.gov/25405662/', \n",
              "'https://pubmed.ncbi.nlm.nih.gov/25564258/']\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">['https://pubmed.ncbi.nlm.nih.gov/28858963/', 'https://pubmed.ncbi.nlm.nih.gov/25405662/', \n",
              "'https://pubmed.ncbi.nlm.nih.gov/25564258/']\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Search Google Scholar and extract publication title (use Google Scholar api)"
      ],
      "metadata": {
        "id": "X2qycNA2BiQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from serpapi import GoogleSearch\n",
        "\n",
        "# Read the API key from the file\n",
        "with open('/content/drive/MyDrive/Deep_learning/api.txt', 'r') as file:\n",
        "    api_key = file.readlines()[7].strip()\n",
        "\n",
        "# Define the search parameters\n",
        "params = {\n",
        "    'engine': 'google_scholar',\n",
        "    'q': 'IgG4-ROD',\n",
        "    'api_key': api_key\n",
        "}\n",
        "\n",
        "# Perform the search\n",
        "search = GoogleSearch(params)\n",
        "results = search.get_dict()\n",
        "organic_results = results['organic_results']\n",
        "\n",
        "# Extract the titles\n",
        "titles = [result['title'] for result in organic_results[:10]]\n",
        "\n",
        "titles\n",
        ""
      ],
      "metadata": {
        "id": "5wmm70Db_uSw",
        "outputId": "16853c5c-bbcf-409d-ecff-b3256fc84832",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['IgG4-related ophthalmic disease. Part II: clinical aspects',\n",
              " 'The treatment outcomes in IgG4‚Äêrelated orbital disease: a systematic review of the literature',\n",
              " 'IgG4-related disease in the eye and ocular adnexa',\n",
              " 'An analysis of IgG4-related disease (IgG4-RD) among idiopathic orbital inflammations and benign lymphoid hyperplasias using two consensus-based diagnostic ‚Ä¶',\n",
              " 'Clinical features and relapse risks of IgG4-related ophthalmic disease: a single-center experience in China',\n",
              " 'The usefulness of infraorbital nerve enlargement on MRI imaging in clinical diagnosis of IgG4-related orbital disease',\n",
              " 'IgG4-related ophthalmic disease. Part I: background and pathology',\n",
              " 'Infraorbital nerve involvement on magnetic resonance imaging in European patients with IgG4-related ophthalmic disease: a specific sign',\n",
              " 'Bilateral IgG4-related ophthalmic disease: a strong indication for systemic imaging',\n",
              " 'Clinical features and symptoms of IgG4-related ophthalmic disease: A multicenter study']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Open-Interpreter playgrounds"
      ],
      "metadata": {
        "id": "4YmO9MCpxyLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter.model = \"gpt-3.5-turbo\"\n"
      ],
      "metadata": {
        "id": "1iRoRvCwN_Vw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter.reset()"
      ],
      "metadata": {
        "id": "SGQMOUkYCydw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message = \"\"\"\n",
        "\n",
        "PubMed\n",
        "https://pubmed.ncbi.nlm.nih.gov/\n",
        "„ÅßIgG4-ROD„ÇíÊ§úÁ¥¢„Åó„Å¶„ÄÅ‰∏ä‰Ωç10È†ÖÁõÆ„ÅÆ„Çø„Ç§„Éà„É´„ÇíË°®„ÅÆÂΩ¢Âºè„ÅßË°®Á§∫„Åï„Åõ„Å¶‰∏ã„Åï„ÅÑ„ÄÇ\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "interpreter.chat(f\"{message}\")"
      ],
      "metadata": {
        "id": "c9lwIw7Ox1ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message = \"\"\"\n",
        "\n",
        "„Åì„ÅÆ„Çà„ÅÜ„Å™ÊÑü„Åò„Åß„ÅÑ„Åë„Çã„Åø„Åü„ÅÑ„Åß„ÅôÔºÅ\n",
        "\n",
        "\n",
        "import requests\n",
        "import json\n",
        "\n",
        "endpoint = 'https://api.semanticscholar.org/graph/v1/paper/search'\n",
        "keyword = 'python'\n",
        "fields = ('title', 'year', 'referenceCount', 'citationCount',\n",
        "    'influentialCitationCount', 'isOpenAccess', 'fieldsOfStudy', 'authors')\n",
        "params = {\n",
        "    'query': keyword,\n",
        "    'fields': ','.join(fields),\n",
        "    'limit': 10\n",
        "}\n",
        "r = requests.get(url=endpoint, params=params)\n",
        "\n",
        "r_dict = json.loads(r.text)\n",
        "total = r_dict['total']\n",
        "print(f'Total search result: {total}')\n",
        "\n",
        "data = r_dict['data']\n",
        "for d in data:\n",
        "    print('---------------')\n",
        "    for fi in fields:\n",
        "        if fi == 'authors':\n",
        "            print(f'{fi}: {list(map(lambda a: a[\"name\"], d[fi]))}')\n",
        "        else:\n",
        "            print(f'{fi}: {d[fi]}')\"\"\"\n",
        "\n",
        "interpreter.chat(f\"{message}\")"
      ],
      "metadata": {
        "id": "WZw-Et__XYqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1wGFVu9MNpM"
      },
      "source": [
        "# Basic Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loqh8HJ-oQAG"
      },
      "source": [
        "## Hello, World!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQGYgFehnumE"
      },
      "source": [
        "Let's start by asking the interpreter to print hello world."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter.chat(\"Please print hello world.\")"
      ],
      "metadata": {
        "id": "sasDzlwm0JAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iixIiFSsn4LZ"
      },
      "source": [
        "Great! The model decided to run a **code block** then tell us its output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VwbdspIofFC"
      },
      "source": [
        "## Math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf-CMTm2oizg"
      },
      "source": [
        "For this example, we're going to open an interactive chat in our terminal with `interpreter.chat()`.\n",
        "\n",
        "üí¨ **The interactive chat behaves exactly like ChatGPT.** üí¨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uytMTyy6qFMd"
      },
      "source": [
        "Try this:\n",
        "\n",
        "1. Ask Open Interpreter to solve an equation like `10x + 14 = 12`\n",
        "2. Watch it use a Python library called `sympy` to solve it.\n",
        "3. Type 'exit' to leave the interactive chat."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "ZpwadxmIoiIR",
        "outputId": "0351a780-ca5d-4f8b-d925-2f6699f65594"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-15 (save_and_display_stream):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/interpreter/code_interpreter.py\", line 369, in save_and_display_stream\n",
            "    raise KeyboardInterrupt\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "interpreter.chat()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-TzGmZ2rVPd"
      },
      "source": [
        "## Web Browsing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QWXsSwarjav"
      },
      "source": [
        "Let's ask Open Interpreter to browse the web.\n",
        "\n",
        "1. Start by opening an interactive chat again with `interpreter.chat()`.\n",
        "2. Type a query like \"what are the last 10 BBC news headlines?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WlB4ArZlbOE"
      },
      "outputs": [],
      "source": [
        "interpreter.chat()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ace0nkv8s66H"
      },
      "source": [
        "Here it likely ran two code blocks:\n",
        "\n",
        "1. The first code block installed `feedparser` from pip.\n",
        "1. The second used `feedparser` to read the BBC's RSS feed.\n",
        "\n",
        "Notice that the first code block **was a shell command.** Open Interpreter uses Jupyter internally, so it can run shell commands *and* Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLWX5tB0rzyW"
      },
      "source": [
        "## Resetting the Chat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZmlAKzjtWJZ"
      },
      "source": [
        "In Python, the Open Interpreter instance remembers your conversation history.\n",
        "\n",
        "If you want it to forget previous messages, you can reset it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQzDB8qetlYH"
      },
      "outputs": [],
      "source": [
        "interpreter.reset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6clx6Pyhtmzj"
      },
      "source": [
        "Now it won't remember the previous examples.\n",
        "\n",
        "<br>\n",
        "\n",
        "`Why might I want to do this?`\n",
        "\n",
        "<br>\n",
        "\n",
        "To reduce the number of tokens that get sent to OpenAI.\n",
        "\n",
        "We need to send OpenAI your entire conversation history (automatically limited to the maximum amount GPT-4 can handle) everytime 1) we send it a message or 2) a code block produces an output.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Note:** The command-line version of Open Interpreter resets itself automatically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC27gX51wCm-"
      },
      "source": [
        "# Advanced Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c73LbswP4YQF"
      },
      "source": [
        "## YouTube Link -> Animation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBAR6xgMSUWX"
      },
      "outputs": [],
      "source": [
        "# Watch the final output:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ultKeJM9wHuz"
      },
      "source": [
        "I've always been fascinated by hand drawn animation. Let's see if we can use Open Interpreter to express that.\n",
        "\n",
        "We'll ask it to redraw every frame in Steve Lacey's \"Bad Habit\" video with `replicate`. They have a service that can redraw images in new styles.\n",
        "\n",
        "<br>\n",
        "\n",
        "`Doesn't this require logging into \"replicate\"?`\n",
        "\n",
        "<br>\n",
        "\n",
        "Yes, and this is a great reason to use Open Interpreter! We can simply log in to `replicate`, then tell the interpreter how to use it ([I just pasted in replicate's quick start](https://replicate.com/jagilley/controlnet-pose/api)).\n",
        "Because code is run locally, the interpreter is \"logged in\" too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oLsybTEwelU"
      },
      "outputs": [],
      "source": [
        "# First, let's install Replicate and log in.\n",
        "\n",
        "!pip install replicate\n",
        "import os\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = \"api_token\" # Get yours: https://replicate.com/account"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVG-vqNgODiK"
      },
      "outputs": [],
      "source": [
        "# Now we'll ask interpreter to redraw the video using Replicate.\n",
        "\n",
        "message = \"\"\"\n",
        "\n",
        "I want to edit a video so it's in 12 fps and each frame is redrawn with ControlNet\n",
        "to give it a stop motion / hand-drawn animation feeling.\n",
        "\n",
        "Here's how you use ControlNet on a single frame, from Replicate's quick start:\n",
        "\n",
        "import replicate\n",
        "output = replicate.run(\n",
        "    \"jagilley/controlnet-canny:aff48af9c68d162388d230a2ab003f68d2638d88307bdaf1c2f1ac95079c9613\",\n",
        "    input={\"image\": open(\"path/to/file\", \"rb\"), \"prompt\": \"<prompt>\"}\n",
        ")\n",
        "\n",
        "(I've noticed that this always returns a list of two links. Just use the second one.)\n",
        "\n",
        "Please download this video and just use the seconds from 0:10 to 0:17:\n",
        "https://www.youtube.com/watch?v=VF-FGf_ZZiI\n",
        "\n",
        "Then reduce it to 12fps, and then replace those frames with ControlNet redraws\n",
        "using random prompts that evoke stop motion / hand-drawn animation--\n",
        "think embroidery, pencil art, claymation, yarn on a table, etc--\n",
        "then add the original sound back.\n",
        "\n",
        "Thanks!\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "interpreter.reset() # Reset the chat\n",
        "interpreter.chat(message) # Pass in the message above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX-g17nXU1JE"
      },
      "source": [
        "<br>\n",
        "\n",
        "Just for fun, imagine a function that takes a `youtube_url`, passes it into `interpreter.chat(message)` with the instructions above, then returns the processed filename:\n",
        "\n",
        "```python\n",
        "def animate_video(youtube_url):\n",
        "  interpreter.reset()\n",
        "  interpreter.message(f'Animate {youtube_url} with the following steps then save to final.mp4. ...')\n",
        "  return 'final.mp4'\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1WSa-Jw0KM0"
      },
      "source": [
        "## Create documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvkatiSHQr8Z"
      },
      "outputs": [],
      "source": [
        "interpreter.reset() # Reset the chat\n",
        "interpreter.chat(\"\"\"Can you make a folder called documents and put five .docx files in it\n",
        "and write a sentence about machine learning in each of them?\"\"\") # Pass a message directly into chat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cM7Yf5pHgeDW"
      },
      "source": [
        "## Edit all documents in a folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1NJy2Y9RRqM"
      },
      "outputs": [],
      "source": [
        "interpreter.reset()\n",
        "interpreter.chat(\"\"\"Go through all the .docx files in my 'documents' folder\n",
        "and replace every occurrence of 'Machine Learning' with 'AI'.\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLgWXbb_ShkE"
      },
      "outputs": [],
      "source": [
        "# If you don't run interpreter.reset(), it will remember your conversation.\n",
        "interpreter.chat(\"I wanted to replace the files, so please delete the old ones and rename the new ones\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlDX4rl8x1EF"
      },
      "source": [
        "## Slow + Reverb a YouTube Link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tun9x2jzx33d"
      },
      "outputs": [],
      "source": [
        "message = \"Can you slow + reverb this song? https://www.youtube.com/watch?v=8GW6sLrK40k\"\n",
        "\n",
        "interpreter.reset()\n",
        "interpreter.chat(message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_uywJFkISTi"
      },
      "outputs": [],
      "source": [
        "# Listen to the final result:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we could open `interpreter.chat()`, ask it to slow it down more, add more reverb, or even create a video with [a .gif backround](https://i.giphy.com/media/zIV7iWK9f0x8Y/giphy.webp)."
      ],
      "metadata": {
        "id": "HjjwO8MUzSiI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9MTDnOWLMP8"
      },
      "source": [
        "## Open Interpreter Artwork"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n540tKZmJ-zt"
      },
      "source": [
        "The artwork for Open Interpreter was illustrated by Open Interpreter. How?\n",
        "\n",
        "It was given a description inspired by [Ruby Chen's](https://rubywjchen.com/) GPT-4 artwork:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEkUr0bju5Sp"
      },
      "outputs": [],
      "source": [
        "message = \"\"\"\n",
        "\n",
        "Hello! I'd like your help making some artwork for the Open Interpreter project.\n",
        "\n",
        "It's going to be pixel art, ~160 wide and 14 pixels tall. Black background.\n",
        "\n",
        "I'd like to see rectangles on every other row. These should be anywhere from\n",
        "~6 to 36 pixels in width. They should be placed randomly around the image, never touching eachother\n",
        "(the space between them should be ~16-64 pixels). They can go off screen / butt up against the edges.\n",
        "\n",
        "Half of these rectangles should be white, half should be a powerful purple color: R138 G43 B226\n",
        "\n",
        "Once you've created it, please scale it up with nearest-neighbor 10x.\n",
        "\n",
        "Please make ~10 options I can review, like banner_1.png, banner_2.png, etc.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "interpreter.reset()\n",
        "interpreter.chat(message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTTkCcIshgmB"
      },
      "source": [
        "## Add subtitles to videos"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`replicate` also has a speech-to-text service that generates subtitle files (.srt).\n",
        "\n",
        "Let's ask Open Interpreter to use some code [copied from replicate's quickstart](https://replicate.com/m1guelpf/whisper-subtitles/api) to add hardcoded subtitles to a video:"
      ],
      "metadata": {
        "id": "NKA7CWtSfrUf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTB3zD5QnJd8"
      },
      "outputs": [],
      "source": [
        "message = \"\"\"\n",
        "Hello! I just logged into Replicate on this machine. You have my permission to run any code.\n",
        "\n",
        "Could you use their speech-to-text service to hardcode subtitles to the bottom of billyking.mp4 and make billy_subbed.mp4?\n",
        "\"\"\"\n",
        "\n",
        "# Again, let's give Open Interpreter an example of how to use the service.\n",
        "message += \"\"\"\n",
        "Here's some code that Replicate provides for how to use their service:\n",
        "\n",
        "import replicate\n",
        "output = replicate.run(\n",
        "    \"m1guelpf/whisper-subtitles:7f686e243a96c7f6f0f481bcef24d688a1369ed3983cea348d1f43b879615766\",\n",
        "    input={\"audio_path\": open(\"path/to/file\", \"rb\")} # Can also be a video path\n",
        ")\n",
        "print(output)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Now let's reset and run Open Interpreter.\n",
        "interpreter.reset()\n",
        "interpreter.chat(message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9v9bo4x2Z3f"
      },
      "source": [
        "You can [watch the output video here.](https://youtube.com/shorts/F6gOzP691po?feature=share)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrgUKfZDLTEa"
      },
      "source": [
        "## YouTube video -> TikTok Clip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxbP1THRwCcp"
      },
      "outputs": [],
      "source": [
        "message = \"\"\"\n",
        "\n",
        "I'd like your help in making a TikTok clip of this: https://www.youtube.com/watch?v=KgHkAwaW_lk\n",
        "\n",
        "Please cut the clip from this -- from 0:15 to 0:38 -- and crop it to portrait (exactly 9:16-- this will be tricky)\n",
        "around the face in the frame. Just follow the face horizontally -- the final video should be as tall as the original.\n",
        "\n",
        "You'll need to smoothly/softly follow the one face in the frame so please smoothly average out the motion\n",
        "between confident face detections. Then put the audio back in. Thanks!\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "interpreter.reset()\n",
        "interpreter.chat(message)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice! It's saved as `cropped_clip_with_audio.mkv`.\n",
        "\n",
        "One problem -- if we want to send it to our phone and upload it to TikTok or YT Shorts, we'll need it to be an `.mp4` file.\n",
        "\n",
        "So, let's just ask for that:"
      ],
      "metadata": {
        "id": "uOyXpFqf3_oJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The interpreter remembers our conversation unless we explicitly .reset() it.\n",
        "interpreter.chat(\"Looks great! Can you convert it to an mp4?\")"
      ],
      "metadata": {
        "id": "84C89ntP4lxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Amazing. Now we can display the final result in Google Colab, too:"
      ],
      "metadata": {
        "id": "1U_yIkHt4yrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Final output:"
      ],
      "metadata": {
        "id": "13UWfW1K3nl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1vMxJzikQ_D"
      },
      "source": [
        "## Bonus: Image -> Animation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another `replicate` example -- let's use ControlNet to turn [this image](https://i.ibb.co/f0p4Q5R/i-heart-victoria-paris.png) into 90s-style animated intro."
      ],
      "metadata": {
        "id": "rVl1c4sMfuoL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWNRJ0Ku8hji"
      },
      "outputs": [],
      "source": [
        "message = \"\"\"\n",
        "Hi, I want to make a video that's comprised of 12 frames. The 12 frames should be of the image\n",
        "victoria.png run through controlnet with different materials as prompts.\n",
        "\n",
        "I'm logged into replicate on this machine. Here's how to use replicate's controlnet:\n",
        "\n",
        "output = replicate.run(\n",
        "    \"jagilley/controlnet-canny:aff48af9c68d162388d230a2ab003f68d2638d88307bdaf1c2f1ac95079c9613\",\n",
        "    input={\"image\": open(\"path/to/file\", \"rb\"), \"prompt\": \"metal\"}\n",
        ")\n",
        "print(output)\n",
        "\n",
        "Can you run victoria.png through this 12 times with different materials each time like \"metal\", \"embroidery\", and \"crayon\"?\n",
        "Then stitch together the 12 pictures into a 1 second video clip. Thank you!\n",
        "\"\"\"\n",
        "\n",
        "interpreter.reset()\n",
        "interpreter.chat(message)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Watch the final output:"
      ],
      "metadata": {
        "id": "QIBeCFA25E_h"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "I1WSa-Jw0KM0",
        "cM7Yf5pHgeDW",
        "YlDX4rl8x1EF",
        "E9MTDnOWLMP8",
        "OTTkCcIshgmB",
        "KrgUKfZDLTEa",
        "C1vMxJzikQ_D"
      ],
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}